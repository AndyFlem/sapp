{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp='../input/monthly/'\n",
    "pref='dam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dam_2016_01', 'json']\n",
      "['dam_2016_02', 'json']\n",
      "['dam_2016_03', 'json']\n",
      "['dam_2016_04', 'json']\n",
      "['dam_2016_05', 'json']\n",
      "['dam_2016_06', 'json']\n",
      "['dam_2016_07', 'json']\n",
      "['dam_2016_08', 'json']\n",
      "['dam_2016_09', 'json']\n",
      "['dam_2016_10', 'json']\n",
      "['dam_2016_11', 'json']\n",
      "['dam_2016_12', 'json']\n",
      "['dam_2017_01', 'json']\n",
      "['dam_2017_02', 'json']\n",
      "['dam_2017_03', 'json']\n",
      "['dam_2017_04', 'json']\n",
      "['dam_2017_05', 'json']\n",
      "['dam_2017_06', 'json']\n",
      "['dam_2017_07', 'json']\n",
      "['dam_2017_08', 'json']\n",
      "['dam_2017_09', 'json']\n",
      "['dam_2017_10', 'json']\n",
      "['dam_2017_11', 'json']\n",
      "['dam_2017_12', 'json']\n",
      "['dam_2018_01', 'json']\n",
      "['dam_2018_02', 'json']\n",
      "['dam_2018_03', 'json']\n",
      "['dam_2018_04', 'json']\n",
      "['dam_2018_05', 'json']\n",
      "['dam_2018_06', 'json']\n",
      "['dam_2018_07', 'json']\n",
      "['dam_2018_08', 'json']\n",
      "['dam_2018_09', 'json']\n",
      "['dam_2018_10', 'json']\n",
      "['dam_2018_11', 'json']\n",
      "['dam_2018_12', 'json']\n",
      "['dam_2019_01', 'json']\n",
      "['dam_2019_02', 'json']\n",
      "['dam_2019_03', 'json']\n",
      "['dam_2019_04', 'json']\n",
      "['dam_2019_05', 'json']\n",
      "['dam_2019_06', 'json']\n",
      "['dam_2019_07', 'json']\n",
      "['dam_2019_08', 'json']\n",
      "['dam_2019_09', 'json']\n",
      "['dam_2019_10', 'json']\n",
      "['dam_2019_11', 'json']\n",
      "['dam_2019_12', 'json']\n",
      "['dam_2020_01', 'json']\n",
      "['dam_2020_02', 'json']\n",
      "['dam_2020_03', 'json']\n",
      "['dam_2020_04', 'json']\n",
      "['dam_2020_05', 'json']\n",
      "['dam_2020_06', 'json']\n",
      "['dam_2020_07', 'json']\n",
      "['dam_2020_08', 'json']\n",
      "['dam_2020_09', 'json']\n",
      "['dam_2020_10', 'json']\n",
      "['dam_2020_11', 'json']\n",
      "['dam_2020_12', 'json']\n",
      "['dam_2021_01', 'json']\n",
      "['dam_2021_02', 'json']\n",
      "['dam_2021_03', 'json']\n",
      "['dam_2021_04', 'json']\n",
      "['dam_2021_05', 'json']\n",
      "['dam_2021_06', 'json']\n",
      "['dam_2021_07', 'json']\n",
      "['dam_2021_08', 'json']\n",
      "['dam_2021_09', 'json']\n",
      "['dam_2021_10', 'json']\n",
      "['dam_2021_11', 'json']\n",
      "['dam_2021_12', 'json']\n",
      "['dam_2022_01', 'json']\n",
      "['dam_2022_02', 'json']\n",
      "['dam_2022_03', 'json']\n",
      "['dam_2022_04', 'json']\n",
      "['dam_2022_05', 'json']\n",
      "['dam_2022_06', 'json']\n",
      "['dam_2022_07', 'json']\n",
      "['dam_2022_08', 'json']\n",
      "['dam_2022_09', 'json']\n",
      "['dam_2022_10', 'json']\n",
      "['dam_2022_11', 'json']\n",
      "['dam_2022_12', 'json']\n",
      "['dam_2023_01', 'json']\n",
      "['dam_2023_02', 'json']\n",
      "['dam_2023_03', 'json']\n",
      "['dam_2023_04', 'json']\n",
      "['dam_2023_05', 'json']\n",
      "['dam_2023_06', 'json']\n",
      "['dam_2023_07', 'json']\n",
      "['dam_2023_08', 'json']\n",
      "['dam_2023_09', 'json']\n"
     ]
    }
   ],
   "source": [
    "onlyfiles = [f for f in listdir(inp) if isfile(join(inp, f))]\n",
    "for f in onlyfiles:\n",
    "\n",
    "    if (f.split('_')[0]==pref and f.split('.')[1]=='json'):\n",
    "        print(f.split('.'))\n",
    "        with open(join(inp, f), \"r\") as read_file:\n",
    "            dat = pd.DataFrame(json.load(read_file))\n",
    "\n",
    "            dat.drop(dat[dat[0] == 'Date:Time'].index, inplace = True)\n",
    "            dat.drop(dat[dat[0] == 'Min'].index, inplace = True)\n",
    "            dat.drop(dat[dat[0] == 'Max'].index, inplace = True)\n",
    "            dat.drop(dat[dat[0] == 'Average'].index, inplace = True)\n",
    "            dat.drop(dat[dat[0] == 'Total'].index, inplace = True)\n",
    "            dat.columns=['datehour','price','volume']\n",
    "            dat['price']=dat['price'].astype(float)\n",
    "            dat['volume']=dat['volume'].astype(float)\n",
    "\n",
    "            dat['date']=pd.to_datetime(dat.datehour.str.slice(1,11),format=\"%Y/%m/%d\")\n",
    "            dat['hour']=dat.datehour.str.slice(13,15).astype(int)\n",
    "\n",
    "            dat=dat.drop(columns=['datehour'],axis=1)\n",
    "            dat.set_index(['date','hour'],inplace=True)\n",
    "            dat.to_csv(inp+f.split('.')[0]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
